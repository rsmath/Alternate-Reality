{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alternate_Reality",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zITuJAv0zX3g",
        "colab_type": "text"
      },
      "source": [
        "#**ALTERNATE REALITY**\n",
        "\n",
        "### **Description**\n",
        "\n",
        "---\n",
        "\n",
        "This is a project that I am working on to apply my newfound skills of Recurrent Neural Networks and Natural Language Processing. This project deals with **text generation** using LSTM RNN's.\n",
        "\n",
        "\n",
        "### **Motivation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I lived in New York City from 2014 to 2018. In the American education system, students write out different things (essays, poems, research papers, op-eds, etc.) on a daily basis.\n",
        "\n",
        "Throughout my time at *The Bronx High School of Science*, I was trained in the art of scientific thinking! I had to write daily homeworks for my english class, most of which I typed up in Google docs. I also wrote numerous research papers for my english and history classes, some of which were well above **20 pages**. All of these texts are my creation. My own piece in the world of words and sentences.\n",
        "\n",
        "When I had to leave *New York City* in the middle of my senior year, I was devastated beyond narration. It was the single most horrifying experience of my life. I was detached from everything I belonged to and stood for (kind of like Thor if you think about it) and banished away. \n",
        "\n",
        "Ever since then, I have not been able to think like I used to be able to. I read text, but I am not critically thinking of it, not finding literary and rhetorical devices that the author used to set a scene, or show the development of a character.\n",
        "\n",
        "And so I turned to **Neural Networks** to help me out. By using **Python**, **Keras**, and **LSTM**, I will be able to create a *Recurrent Neural Network* for language modeling and sample new text written in my style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iokuQUsJI2U",
        "colab_type": "code",
        "outputId": "b9dbb7ad-927b-4a71-c89b-28ffe4e49800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "mounting the google drive to use text data and to clone GItHub repositories\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHeR_2ESIAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "important libraries imported\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import os, io, sys, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Activation, Dropout, Input, Lambda, Reshape, Masking\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-WKyhazY0jD",
        "colab_type": "code",
        "outputId": "fd7552b1-a730-4d2f-e222-99124a5ae2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "making sure tensorflow's version2 is used in this notebook\n",
        "\"\"\"\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "\n",
        "if int(tf.__version__[0]) < 2:\n",
        "  !pip install tensorflow==2.1\n",
        "\n",
        "print(\"Tensorflow version: \" + tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Tensorflow version: 2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKm3VjU9Sv0u",
        "colab_type": "code",
        "outputId": "e4661c7a-4712-4121-ae01-02be0077ecc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"\n",
        "testing if connected to TPU and/or GPU\n",
        "\"\"\"\n",
        "\n",
        "import pprint\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('Not connected to a TPU runtime.')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('Connected to TPU.\\n\\nTPU address is', tpu_address)\n",
        "\n",
        "  with tf.compat.v1.Session((tpu_address)) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n",
        "if tf.test.gpu_device_name() == '':\n",
        "  print('\\n\\nNot connected to a GPU runtime.')\n",
        "else:\n",
        "  print('\\n\\nConnected to GPU: ' + tf.test.gpu_device_name())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not connected to a TPU runtime.\n",
            "\n",
            "\n",
            "Not connected to a GPU runtime.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PeaGO82CB9",
        "colab_type": "code",
        "outputId": "6bbc9e72-8d8c-41f1-e5a8-cb2f84258a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"\n",
        "cleaning the data and forming the examples\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "\n",
        "path = \"/content/drive/My Drive/Alternate-Reality/folder/text_data/merged.txt\"\n",
        "\n",
        "with io.open(path, encoding='utf-8') as corpus:\n",
        "    text = corpus.read()\n",
        "\n",
        "LENGTH = len(text)\n",
        "Tx = 11 # length of each example (characters)\n",
        "\n",
        "vocab = sorted(set(list(text))) # list (a set actually) of all the characters in the corpus\n",
        "char_to_indices = dict((ch, idx) for idx, ch in enumerate(vocab))\n",
        "index_to_char = dict((idx, ch) for idx, ch in enumerate(vocab))\n",
        "\n",
        "# pretty much temporary variables just for the sake of splitting the huge corpus\n",
        "sentences = [] # X\n",
        "mapped_chars = [] # Y\n",
        "\n",
        "step = 3\n",
        "\n",
        "for i in range(0, LENGTH - Tx, step):\n",
        "    temp_text = text[i: i+Tx]\n",
        "    sentences.append(temp_text[:-1])\n",
        "    mapped_chars.append(temp_text[-1])\n",
        "\n",
        "m = len(sentences)\n",
        "\n",
        "X = np.zeros((m, Tx - 1, len(vocab)))\n",
        "Y = np.zeros((m, len(vocab)))\n",
        "\n",
        "for i, example in enumerate(sentences):\n",
        "    X[i, :, :] = one_hot([char_to_indices[ch] for ch in example], depth=len(vocab))\n",
        "    Y[i, :] = one_hot(char_to_indices[mapped_chars[i]], depth=len(vocab))\n",
        "\n",
        "# a nuisance is fixed by turning X and Y into numpy arrays\n",
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)\n",
        "\n",
        "#==============printing data dimesions=========================================\n",
        "print(f\"Length of corpus: {LENGTH}\")\n",
        "print(f\"X.shape = {X.shape}\")\n",
        "print(f\"Y.shape = {Y.shape}\")\n",
        "print(f\"Number of examples: {m}\") "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of corpus: 229570\n",
            "X.shape = (76520, 10, 96)\n",
            "Y.shape = (76520, 96)\n",
            "Number of examples: 76520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kzEifE0OT_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "read the function docstring below\n",
        "\"\"\"\n",
        "\n",
        "def get_example(index=None):\n",
        "    \"\"\"\n",
        "    retrieves the example at index position in X is index is passed, otherwise random example is obtained\n",
        "    :param index: index of example desired to be retrieved\n",
        "    :return: string of text\n",
        "    \"\"\"\n",
        "\n",
        "    if index is None:\n",
        "        index = np.random.randint(low=0, high=m)\n",
        "\n",
        "    curr_x = [index_to_char[idx] for idx in np.argmax(X[index, :, :], axis=1)]\n",
        "    curr_y = index_to_char[np.argmax(Y[index, :])]\n",
        "\n",
        "    x_y = (''.join(curr_x), curr_y)\n",
        "\n",
        "    return x_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYgE7ygSLTu",
        "colab_type": "code",
        "outputId": "76e5a7f6-daea-4225-8f39-b169bedb938b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"\n",
        "testing a single example and the time it took to retrieve it\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.process_time()\n",
        "example = get_example()\n",
        "end = time.process_time()\n",
        "\n",
        "print(f\"Sample X: {example[0]}\\nCorresponding Y: {example[1]}\")\n",
        "print(f\"\\nTime taken for acquiring this example: {end - start} seconds\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample X: im enough \n",
            "Corresponding Y: p\n",
            "\n",
            "Time taken for acquiring this example: 0.0006067969999996592 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPLZQqNSwuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "network architecture creation\n",
        "model creation\n",
        "plot_model allows me to see what my neural network looks like\n",
        "\"\"\"\n",
        "\n",
        "def Ram_Says(Tx, vocab, output_length):\n",
        "  # network architecture LSTM -> Dropout -> Reshape -> LSTM -> Dropout -> Dense\n",
        "\n",
        "  # define the initial hidden state a0 and initial cell state c0\n",
        "  a0 = Input(shape=(output_length,), name='a0')\n",
        "  c0 = Input(shape=(output_length,), name='c0')\n",
        "  a = a0\n",
        "  c = c0\n",
        "\n",
        "  X = Input(shape=(Tx, len(vocab)), name='X')\n",
        "  \n",
        "  a, _, c = LSTM(units=output_length, activation='tanh', return_state=True, dtype='float32', name=f'lstm_1')(X, [a, c])\n",
        "  a = Dropout(rate=0.2, name=f'dropout_1')(a)\n",
        "  a = Reshape((1, output_length), name='reshape_1')(a) # needed after a dropout layer for another LSTM layer\n",
        "  a = LSTM(units=output_length, activation='tanh', dtype='float32', name=f'lstm_2')(a)\n",
        "  a = Dropout(rate=0.2, name=f'dropout_2')(a)\n",
        "  out = Dense(units=len(vocab), activation='softmax', name=f'dense')(a)\n",
        "    \n",
        "  model = Model(inputs=[X, a0, c0], outputs=out, name='Ram')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTikSyoerWZ",
        "colab_type": "code",
        "outputId": "eb3fd799-6c36-4041-8397-4b5571188217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\"\"\"\n",
        "creating the model and the summary of it\n",
        "\"\"\"\n",
        "#====================Creating important variables===============================\n",
        "n_a = 256 # number of hidden state dimensions for each LSTM cell\n",
        "\n",
        "a0 = np.zeros((m, n_a))\n",
        "c0 = np.zeros((m, n_a))\n",
        "#===============================================================================\n",
        "\n",
        "model = Ram_Says(Tx=Tx - 1, vocab=vocab, output_length=n_a)\n",
        "\n",
        "plot_model(model, to_file='/content/drive/My Drive/Alternate-Reality/nn_graph.png')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Ram\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X (InputLayer)                  [(None, 10, 96)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "a0 (InputLayer)                 [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 361472      X[0][0]                          \n",
            "                                                                 a0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 256)       0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 256)          525312      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 96)           24672       dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 911,456\n",
            "Trainable params: 911,456\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFzkBWLkMA94",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "configuring optimizations for the model\n",
        "fitting the model\n",
        "\"\"\"\n",
        "\n",
        "learning_rate = 0.01\n",
        "learning_rate_decay = 0.001\n",
        "\n",
        "optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=learning_rate_decay)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 8192\n",
        "\n",
        "model.fit([X, a0, c0], Y, batch_size=batch_size, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXexPfExcpNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "filepath\n",
        "\"\"\"\n",
        "\n",
        "filepath = '/content/drive/My Drive/Alternate-Reality/Ram_Says_Trained_Model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrScYNaRlFr",
        "colab_type": "code",
        "outputId": "3c230d3b-3075-4cd8-b7df-47f4f338e0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"\n",
        "this code takes care of saving the new model only if its accuracy is better than\n",
        "that of the last model\n",
        "\"\"\"\n",
        "\n",
        "if os.path.exists(filepath):\n",
        "  prev_model = load_model(filepath)\n",
        "  prev_acc = prev_model.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "  curr_acc = model.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "  if curr_acc > prev_acc:\n",
        "    print(\"There was a previous model saved.\")\n",
        "    print(f\"Previous accuracy: {round(prev_acc*100, 2)}%\")\n",
        "    print(f\"Current accuracy: {round(curr_acc*100, 2)}%\")\n",
        "    model.save(filepath)\n",
        "    print('New model is saved.')\n",
        "  else:\n",
        "    print(f\"Previous accuracy: {round(prev_acc*100, 2)}%\")\n",
        "    print(f\"Current accuracy: {round(curr_acc*100, 2)}%\")\n",
        "    print('Old model is kept.')\n",
        "else: # if this is the first time saving the model\n",
        "  model.save(filepath)\n",
        "  print('First time model is saved.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There was a previous model saved.\n",
            "Previous accuracy: 96.75%\n",
            "Current accuracy: 96.78%\n",
            "New model is saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HojRFbuhdgze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "loading the model for sampling\n",
        "\"\"\"\n",
        "\n",
        "Ram_says = load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw-XXtYuYJ-8",
        "colab_type": "code",
        "outputId": "777eeb3a-d647-4f07-8989-c74491d3ff50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "testing the accuracy of the model on X and Y\n",
        "\"\"\"\n",
        "\n",
        "accuracy = Ram_says.evaluate([X, a0, c0], Y, verbose=0)[1]\n",
        "print(f\"Accuracy on the training set: {round(accuracy*100, 2)}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the training set: 96.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHJwSspvMVkp",
        "colab_type": "code",
        "outputId": "511192db-9c96-4325-edd2-125961cb9dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\"\"\"\n",
        "text sampling time\n",
        "\"\"\"\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def generate_output():\n",
        "      diversity = random.choice([0.2, 0.5, 0.7, 1.0, 1.2, 1.4])\n",
        "      diversity = 0.2\n",
        "      print(f'Diversity: {diversity}')\n",
        "      generated = ''\n",
        "      sentence = input('Your text: ')\n",
        "      generated += sentence\n",
        "      if len(sentence) > 10:\n",
        "        sentence = sentence[:10]\n",
        "      elif len(sentence) < 10:\n",
        "        rem = 10 - len(sentence)\n",
        "        sentence += ' ' * rem\n",
        "      sys.stdout.write(generated + ' ')\n",
        "      a0 = np.zeros((1, n_a))\n",
        "      c0 = np.zeros((1, n_a))\n",
        "      sys.stdout.write(sentence)\n",
        "      for i in range(1000):\n",
        "          x_pred = np.zeros((1, Tx-1, len(vocab)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              if char != '0':\n",
        "                  x_pred[0, t, char_to_indices[char]] = 1.\n",
        "          preds = Ram_says.predict([x_pred, a0, c0], verbose=0)[0]\n",
        "          next_index = sample(preds, temperature = 1.0)\n",
        "          next_char = index_to_char[next_index]\n",
        "\n",
        "          generated += next_char\n",
        "          sentence = sentence[1:] + next_char\n",
        "\n",
        "          sys.stdout.write(next_char)\n",
        "          sys.stdout.flush()\n",
        "\n",
        "          if next_char == '\\n':\n",
        "              print('\\n')\n",
        "          elif next_char == '\\t':\n",
        "              print('\\t')\n",
        "\n",
        "generate_output()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diversity: 0.2\n",
            "Your text: The\n",
            "The The                                 Date-10foce deneed to ave the police of the sent to be some known as “To loon duberd many as it is to New York, to his domestic oil for a long of the weap in Congress she had ease and ensore considerable spending neges and cered to confinced the not on that is a senter aftarity, and a communist confidend ming the enemonity of Congress, complelated to make me to ausheres decart did not prife to meacunion of the Indians, if the stopled. And order to be the same that I am good family defense does money starting ut from America. a recatted to the 1972 Nair ance me to eventle, to stay the cares and even Dieanation, even to geter from the British other trages in Robard on New Yer proved a coffitted them in 1975, up they wanted to raised her free that they will be jasunang but was is the mind end hand of the part endere to the money starting under President during the reader to the side because Opea which states who arm diresten to whith with whith security plannerd "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_orRDcEbn3i",
        "colab_type": "text"
      },
      "source": [
        "# I will be placing the model's generated text below for record."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEeSqIBI8nuH",
        "colab_type": "text"
      },
      "source": [
        " > \"My name is Ramansh Sharma My name is the public control considered to fut tell overt of a decide the world to life people real and massive really came to congres to be streated it could have ingarding the world many that estabe by nugues and could have been guvern for the Soligition, purched that remamplogr prices repective independence in 1982. Bech of 1980ided to social and enjoyable capting the sent a see that her seperones in Am\" - Ram_says\n",
        "\n",
        "Pretty good for a first try for a character level model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1yBAYAUakgJ",
        "colab_type": "text"
      },
      "source": [
        "> My name is Ram My name is for the fight not started with a being at left the sade but the colonists clear of the Dept-A spondin surmerity, Konusansingtond that in the US and CIA port and scange and industed the Cold War and Congress in Depertmant in reace in the different id on the eneming American relations going to see servions. He also failed in his becuuse to the ready the Ford she end and commercesvestromes to onder the shooked a protects the treaty proved my team America in aid of the new that her strect of phy incrusing and of the pagome, he hading the didrition in 1982. After their visto want in the Cold War which movern of the fen his “In and wenter for their marking of confisens than his prorecive in front of a contriluting as a \"confid and the Office of Economic Opportunity. He also failed in his fail w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSeb-T2b0FY",
        "colab_type": "text"
      },
      "source": [
        "> Thor is the king Thor is the rare to be some known as the enemonity of Congress, the meint in the Cold War when Chine with them. I was also high domination which dickins of Curness, he will be a beation….ther would reduce the decision of appressed nor the increased communist against controlles. Perretimmert. Itay of nuclas they gave he was a tork the side and very impossing this him as a facutive promest it be a stay a and fack as the anities and the EPand and being people white Sinally sochiets. He did not convered congresity. \n",
        "\n",
        "\n",
        "> o show he was the niting to the 1987 in are income taxes. Truean aid to the child of cotting in country, this be mistaky was allice the new that were because Opeaa Act goush in the Cold War and Congress dissided on I came to that felt me to event, and the INation He was was a Soviet troops,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLcz3Dl327C5",
        "colab_type": "text"
      },
      "source": [
        "> The The                                 Date-10foce deneed to ave the police of the sent to be some known as “To loon duberd many as it is to New York, to his domestic oil for a long of the weap in Congress she had ease and ensore considerable spending neges and cered to confinced the not on that is a senter aftarity, and a communist confidend ming the enemonity of Congress, complelated to make me to ausheres decart did not prife to meacunion of the Indians, if the stopled. And order to be the same that I am good family defense does money starting ut from America. a recatted to the 1972 Nair ance me to eventle, to stay the cares and even Dieanation, even to geter from the British other trages in Robard on New Yer proved a coffitted them in 1975, up they wanted to raised her free that they will be jasunang but was is the mind end hand of the part endere to the money starting under President during the reader to the side because Opea which states who arm diresten to whith with whith security plannerd "
      ]
    }
  ]
}